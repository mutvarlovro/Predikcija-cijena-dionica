{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from fastdtw import fastdtw, dtw\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ABBV        ABC        ABT         ACN    ADBE        ADI  \\\n",
      "date                                                                         \n",
      "2013-06-03  37.035571  49.114233  33.653966   74.327146   43.46  40.921428   \n",
      "2013-06-04  37.266189  49.654974  33.327932   73.557620   44.39  41.198287   \n",
      "2013-06-05  36.762246  49.319342  32.875106   72.045728   43.84  40.537399   \n",
      "2013-06-06  37.155151  48.993032  33.183027   72.018569   43.57  40.608847   \n",
      "2013-06-07  37.582221  49.356634  33.970943   73.240757   44.12  41.269734   \n",
      "...               ...        ...        ...         ...     ...        ...   \n",
      "2017-03-31  63.502713  87.307568  43.689744  117.506015  130.13  81.046642   \n",
      "2017-04-03  63.376020  86.153332  43.748771  115.310374  129.59  80.344469   \n",
      "2017-04-04  63.453985  85.758721  43.463474  115.702453  130.04  80.344469   \n",
      "2017-04-05  63.307800  86.005353  43.089637  115.310374  129.89  79.157697   \n",
      "2017-04-06  63.424748  86.459155  42.961746  114.496811  130.15  79.434610   \n",
      "\n",
      "                   ADP   ADSK        AEE        AEP  ...        WYNN  \\\n",
      "date                                                 ...               \n",
      "2013-06-03   54.959692  37.38  28.229158  39.005194  ...  122.126106   \n",
      "2013-06-04   54.501365  36.70  28.345808  38.929111  ...  121.011849   \n",
      "2013-06-05   53.624222  36.12  28.370804  38.557150  ...  118.305796   \n",
      "2013-06-06   53.687440  35.97  28.495785  38.607872  ...  119.331620   \n",
      "2013-06-07   54.453952  36.65  29.087365  39.013647  ...  121.595507   \n",
      "...                ...    ...        ...        ...  ...         ...   \n",
      "2017-03-31  101.285014  86.47  53.767458  65.466800  ...  113.336848   \n",
      "2017-04-03  100.177101  85.39  53.747759  65.486304  ...  115.047630   \n",
      "2017-04-04  100.355158  84.95  53.895499  65.622836  ...  115.443186   \n",
      "2017-04-05  100.829978  83.54  54.220527  66.149457  ...  115.383853   \n",
      "2017-04-06  100.651921  84.07  53.885650  65.944660  ...  116.540856   \n",
      "\n",
      "                  XEL         XL       XLNX        XOM       XRAY        XRX  \\\n",
      "date                                                                           \n",
      "2013-06-03  24.568580  28.537369  36.412208  78.891863  41.211051  31.829699   \n",
      "2013-06-04  24.560070  28.619478  36.519910  78.313932  40.898772  32.151572   \n",
      "2013-06-05  24.236687  28.099456  36.259630  77.330587  40.430354  31.293243   \n",
      "2013-06-06  24.602620  28.327536  35.694196  77.830886  40.137593  31.472062   \n",
      "2013-06-07  24.806862  28.564739  36.439133  78.883237  40.410837  32.795319   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2017-03-31  43.791540  39.433020  57.259296  80.461695  62.265399  29.082261   \n",
      "2017-04-03  43.742281  38.977947  56.557031  80.520562  62.464840  28.725666   \n",
      "2017-04-04  43.850651  39.294519  56.507576  80.814898  61.607245  28.567180   \n",
      "2017-04-05  44.156059  38.958161  56.032805  80.971878  61.816657  28.369072   \n",
      "2017-04-06  43.929466  39.373662  55.726183  81.442815  62.863721  28.250207   \n",
      "\n",
      "                  XYL        YUM       ZION  \n",
      "date                                         \n",
      "2013-06-03  26.464742  45.092601  26.757166  \n",
      "2013-06-04  26.099388  44.994588  26.292329  \n",
      "2013-06-05  25.481097  44.452248  25.720967  \n",
      "2013-06-06  25.574777  46.471320  26.079279  \n",
      "2013-06-07  25.808978  48.039531  26.505379  \n",
      "...               ...        ...        ...  \n",
      "2017-03-31  49.766969  63.346098  41.806363  \n",
      "2017-04-03  49.003915  62.999132  41.577424  \n",
      "2017-04-04  49.915616  63.286618  41.467931  \n",
      "2017-04-05  49.975075  63.316358  40.860743  \n",
      "2017-04-06  50.460654  63.990464  41.308668  \n",
      "\n",
      "[970 rows x 368 columns]\n",
      "                ABBV       ABC       ABT       ACN      ADBE       ADI  \\\n",
      "date                                                                     \n",
      "2013-06-04  0.006208  0.010950 -0.009735 -0.010407  0.021173  0.006743   \n",
      "2013-06-05 -0.013615 -0.006782 -0.013680 -0.020768 -0.012468 -0.016172   \n",
      "2013-06-06  0.010631 -0.006638  0.009323 -0.000377 -0.006178  0.001761   \n",
      "2013-06-07  0.011429  0.007394  0.023467  0.016828  0.012544  0.016143   \n",
      "2013-06-10 -0.001820  0.014440 -0.000533  0.008003 -0.000680 -0.005642   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2017-03-31 -0.004593 -0.007206 -0.003147 -0.005324  0.004004 -0.003046   \n",
      "2017-04-03 -0.001997 -0.013309  0.001350 -0.018862 -0.004158 -0.008702   \n",
      "2017-04-04  0.001229 -0.004591 -0.006543  0.003394  0.003466  0.000000   \n",
      "2017-04-05 -0.002306  0.002872 -0.008638 -0.003394 -0.001154 -0.014881   \n",
      "2017-04-06  0.001846  0.005263 -0.002972 -0.007080  0.002000  0.003492   \n",
      "\n",
      "                 ADP      ADSK       AEE       AEP  ...      WYNN       XEL  \\\n",
      "date                                                ...                       \n",
      "2013-06-04 -0.008374 -0.018359  0.004124 -0.001952  ... -0.009166 -0.000346   \n",
      "2013-06-05 -0.016225 -0.015930  0.000881 -0.009601  ... -0.022616 -0.013254   \n",
      "2013-06-06  0.001178 -0.004161  0.004396  0.001315  ...  0.008634  0.014985   \n",
      "2013-06-07  0.014176  0.018728  0.020548  0.010455  ...  0.018794  0.008267   \n",
      "2013-06-10 -0.001888 -0.018728 -0.007187 -0.005214  ...  0.010562 -0.000343   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2017-03-31  0.002151  0.001736 -0.001830 -0.000447  ...  0.002708  0.003155   \n",
      "2017-04-03 -0.010999 -0.012569 -0.000366  0.000298  ...  0.014982 -0.001125   \n",
      "2017-04-04  0.001776 -0.005166  0.002745  0.002083  ...  0.003432  0.002474   \n",
      "2017-04-05  0.004720 -0.016737  0.006013  0.007993  ... -0.000514  0.006941   \n",
      "2017-04-06 -0.001767  0.006324 -0.006195 -0.003101  ...  0.009977 -0.005145   \n",
      "\n",
      "                  XL      XLNX       XOM      XRAY       XRX       XYL  \\\n",
      "date                                                                     \n",
      "2013-06-04  0.002873  0.002953 -0.007353 -0.007606  0.010062 -0.013901   \n",
      "2013-06-05 -0.018337 -0.007153 -0.012636 -0.011519 -0.027059 -0.023975   \n",
      "2013-06-06  0.008084 -0.015717  0.006449 -0.007267  0.005698  0.003670   \n",
      "2013-06-07  0.008339  0.020655  0.013430  0.006785  0.041186  0.009116   \n",
      "2013-06-10  0.007319 -0.005681 -0.003615  0.000000  0.004353 -0.001817   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2017-03-31 -0.007000  0.000173 -0.020398 -0.003358 -0.005435  0.006392   \n",
      "2017-04-03 -0.011607 -0.012340  0.000731  0.003198 -0.012337 -0.015451   \n",
      "2017-04-04  0.008089 -0.000875  0.003649 -0.013824 -0.005533  0.018434   \n",
      "2017-04-05 -0.008597 -0.008437  0.001941  0.003393 -0.006959  0.001190   \n",
      "2017-04-06  0.010609 -0.005487  0.005799  0.016796 -0.004199  0.009670   \n",
      "\n",
      "                 YUM      ZION  \n",
      "date                            \n",
      "2013-06-04 -0.002176 -0.017525  \n",
      "2013-06-05 -0.012127 -0.021971  \n",
      "2013-06-06  0.044420  0.013835  \n",
      "2013-06-07  0.033189  0.016207  \n",
      "2013-06-10 -0.014385  0.018821  \n",
      "...              ...       ...  \n",
      "2017-03-31 -0.001876 -0.009007  \n",
      "2017-04-03 -0.005492 -0.005491  \n",
      "2017-04-04  0.004553 -0.002637  \n",
      "2017-04-05  0.000470 -0.014751  \n",
      "2017-04-06  0.010590  0.010903  \n",
      "\n",
      "[969 rows x 368 columns]\n"
     ]
    }
   ],
   "source": [
    "reduced = pd.read_csv(\"reduced.csv\", index_col=\"date\")\n",
    "d = reduced.apply(np.log).diff()[1:]\n",
    "data = []\n",
    "for podatak in d[\"ABBV\"]:\n",
    "    data.append(podatak)\n",
    "d.shape\n",
    "print(reduced)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[[ 0.00620763 -0.01361507  0.01063102 ... -0.00577969 -0.04238826\n",
      "   0.00650997]\n",
      " [-0.01361507  0.01063102  0.0114287  ... -0.04238826  0.00650997\n",
      "   0.01431664]\n",
      " [ 0.01063102  0.0114287  -0.00181984 ...  0.00650997  0.01431664\n",
      "   0.00047371]\n",
      " ...\n",
      " [-0.02490616 -0.00157743  0.01046947 ... -0.01601987  0.02235665\n",
      "  -0.01301865]\n",
      " [-0.00157743  0.01046947  0.01396213 ...  0.02235665 -0.01301865\n",
      "  -0.01489014]\n",
      " [ 0.01046947  0.01396213  0.00665361 ... -0.01301865 -0.01489014\n",
      "  -0.00527215]]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "L = len(data)\n",
    "l = 20\n",
    "s = 1\n",
    "\n",
    "X = np.stack([data[i:i + l] for i in range(L // 2 - l - s)])\n",
    "Y = np.stack([data[i + l + s - 1] > data[i + l - 1] for i in range(L // 2 - l - s)]).astype(np.float32)\n",
    "##ako je sljedeći element veći od zadnjeg clana niza onda dobiva 1 inace 0\n",
    "\n",
    "X_test = np.stack([data[i:i + l] for i in range(L // 2, L - l - s)])\n",
    "Y_test = np.stack([data[i + l + s - 1] > data[i + l - 1] for i in range(L // 2, L - l - s)]).astype(np.float32)\n",
    "print(len(X[0]))\n",
    "print(X)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 464, 0.49892008, 0.48922414)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X_test), Y.mean(), Y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "m = len(X_test)\n",
    "kernel_train = np.empty((n, n))\n",
    "kernel_test = np.empty((m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4251.3177053928375\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for i in range(n):\n",
    "    for j in range(i+1):\n",
    "        if i == j:\n",
    "            kernel_train[i][j] = 0.0\n",
    "        else:\n",
    "            kernel_train[i][j] = kernel_train[j][i] = fastdtw(X[i], X[j], radius = 5, dist = 2)[0]\n",
    "\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):           \n",
    "        kernel_test[i][j] = fastdtw(X_test[i], X[j], radius = 5, dist = 2)[0]\n",
    "                      \n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_train = np.load(\"kernel_train_univariant_ABBV.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test = np.load(\"kernel_test_univariant_ABBV.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train:  0.7580993520518359\n",
      "AUC train: 0.7580515748619197\n"
     ]
    }
   ],
   "source": [
    "c = 10\n",
    "gamma = 25\n",
    "kernel = np.exp(-kernel_train/gamma)\n",
    "testkernel = np.exp(-kernel_test/gamma)\n",
    "clf = svm.SVC(kernel='precomputed', C=c)\n",
    "clf.fit(kernel, Y)\n",
    "#res = clf.predict(testkernel) #test\n",
    "res = clf.predict(kernel) #train\n",
    "#print('accuracy test: ', np.mean(res == Y_test))\n",
    "#print('AUC test:', roc_auc_score(Y_test, res))\n",
    "print('accuracy train: ', np.mean(res == Y))\n",
    "print('AUC train:', roc_auc_score(Y, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166,  71],\n",
       "       [ 54, 173]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, res)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
